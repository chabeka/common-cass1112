#Cassandra Configuration Properties
cassandra.cql.hosts=@GED.HOSTS_CASSANDRA_DFCE@
cassandra.cql.port=9042
cassandra.cluster.name=@GED.CASSANDRA_CLUSTER_NAME@
cassandra.cql.keyspace.name=dfce
cassandra.cql.consistency.read=QUORUM
cassandra.cql.consistency.write=QUORUM
cassandra.cql.max.local.connections=8
cassandra.cql.max.remote.connections=2
cassandra.cql.load.balancing.policy=com.datastax.driver.core.policies.RoundRobinPolicy
cassandra.cql.retry.policy=com.datastax.driver.core.policies.DefaultRetryPolicy
#Change to RF2 to get RF2 failover configuration
cassandra.keyspace.strategy=default
cassandra.replication.factor=1
cassandra.max.active.connections=200
cassandra.load.balancing.policy=me.prettyprint.cassandra.connection.RoundRobinBalancingPolicy

#Cassandra batch mode UNLOGGED, LOGGED, ASYNC
cassandra.batch.mode=LOGGED
#Cassandra authentication
cassandra.username=root
#cassandra.password=regina4932
cassandra.password=YwFLg1owCXyfFVhKH+mU/g==

#number of rows in one page returned by the server
cassandra.paging.size=100

#Lock Strategy

lock.strategy=cassandra
cassandra.lock.ttl=5000
#
# Search server configuration
#
# Comma separated list of host declarations: hostname[:port]
search.server.hosts=localhost
#search.server.protocol=http
search.server.port=9200
#search.server.username=
#search.server.password=
#search.server.timeout.connection=1000
#search.server.timeout.connection.request=2000
#search.server.max.connections.per.route=100
#search.server.max.connections.total=200
#search.server.timeout.socket=30000
#search.server.timeout.queries=10000
#search.server.newIndices.settings.number_of_shards=5
#search.server.newIndices.settings.number_of_replicas=1
#search.server.newIndices.settings.max_result_window=10000
search.server.newIndices.settings.analysis.analyzer.default={"tokenizer":"whitespace","filter":["lowercase"]}
#search.server.sniff.timeout=1000
#search.server.sniff.interval=300000
#search.server.sniff.after_failure=60000
search.number.results.limit.es=10000

#LifeCycle
life.cycle.default.length=10
life.cycle.default.unit=YEAR
life.cycle.default.thumbnail.page=1
life.cycle.default.thumbnail.size=TINY
life.cycle.default.thumbnail.quality=1.0
life.cycle.default.thumbnail.mime.type=image/jpeg


#Default search sort
search.default.sort.activated=false
search.default.sort.category.formatted.name=sm_archivage_date
search.default.sort.reversed=true

#Document
#Possible value are MD5, SHA, SHA-256, SHA-384 and SHA-512
document.message.digest.algorithm=SHA-1

#Chunk properties for file storage.
chunk.size=102400

dictionary.dao.max.query.size=100
#Range column size for counter update.
index.counter.query.size=5000
index.reader.numdocs=10000
object.mapper.max.query.size=10000

#statistics
stat.result.max.size=10000

#Lucandra
lucandra.indexname=DOCUBASE

supported.file.types=PDF,DOC,TXT,TMP,GZ,XML,TIF,TIFF,DOCX,DOCM,ODT,XLS,XLSX,XLSM,XLSB,ODS,JPG,JPEG,PNG,HTM,HTML,EML,ZIP,JPE,GIF,XPS,1,VCF,IMA,DTF,MHT,ATT,2,3,4,5,XML,6,7,RTF,8,BMP,9,10,EMZ,CSV,11,DOT,URL,12,15,MSO,16,NON,13,FAX,BCR,DSN,FMM,14,EXE,P7S,17,PPT,PPTX,PPTM,201,18,19,20,DS_,21,AXX,LST,LOG,9K%,VEG,2A3,25,33,DNT,0,26,24,27,32,22,AFF,28,DAT,29,JSF,30,CON,EDI,31,23,D%C,DU,FIC,FR,SOL,SAI,SAR,ROC,SVG,DEM,PD,DEP,MAN,UND,SXW,AGR,XLT,ASC,DSI,37,151,85,MEG,MUS,SNP,34,OXP,YAC,XXX,35,COM,RAP,LEB,KOP,RIB,36,MES,TI,UNI,%3D,_1_,_2_,2A3,AVI,BOR,COU,DE%,DRM,ENT,ENV,FIL,IMG,JUS,MOR,MSG,PAJ,PAR,PIE,POR,PRE,REF,RSI,SOG,TMP,WEB,XNK,164,248,657,1PD,9D6,BAP,BLO,DEC,DET,DUC,ECO,ICO,INI,JP2,LIA,MD,OIE,PAG,URS,237,AI,CCC,CRE,PAS,PAY,148,CHR,DAD,LA%,LNK,NOU,REN,SAL,WPS,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,7Z,AF%,BIN,DUE,FED,HEA,LET,M2,N%C,UNT,131,149,_FI,CAR,DAS,PHO,TRE,0,2,CAP,ETA,REC,SIT,TR,ZZD,123,500,519,716,776,860,867,897,AME,ANN,COP,DB,DOS,EXT,ODI,PLA,SMI,UKN,XLR,454,RAR,001,DO,LNV,LOC,NUM,ODP
supported.file.excluded.types=

daily.log.archive.base.name=DAILY_LOG_ARCHIVE_BASE
daily.log.archive.batch.size=50
event.jobs.log.periodicity=10000

#Cache configuration
# global cache configuration,
# cache.max.entries : number of entries that can be cached.
# cache.ttl : time to live in seconds.
# cache.tti : time to idle in seconds.
# each cache can have a specific configuration by adding :
# cache.[cachename].max.entries : number of entries that can be cached.
# cache.[cachename].ttl : time to live in seconds.
# cache.[cachename].tti : time to idle in seconds.
# available cache names are : base, metadata, chunk, compositeindexreference, contentrepository, file, indexreference, key, user, usergroup

cache.max.entries=100
cache.ttl=120
cache.tti=120

cache.metadata.max.entries=1000
cache.metadata.ttl=600
cache.metadata.tti=600

cache.chunk.max.entries=100
cache.chunk.ttl=600
cache.chunk.tti=300

cache.compositeindexreference.max.entries=1000
cache.compositeindexreference.ttl=600
cache.compositeindexreference.tti=600

cache.contentrepository.max.entries=100
cache.contentrepository.ttl=600
cache.contentrepository.tti=600

cache.file.max.entries=100
cache.file.ttl=600
cache.file.tti=600

cache.indexreference.max.entries=1000
cache.indexreference.ttl=600
cache.indexreference.tti=600

cache.key.max.entries=100
cache.key.ttl=180
cache.key.tti=180

cache.user.max.entries=100
cache.user.ttl=86400
cache.user.tti=86400

cache.usergroup.max.entries=100
cache.usergroup.ttl=86400
cache.usergroup.tti=86400


# pre-populate cache on DFCE start (true / false)
# set this to true if you want to pre-load "hot" caches on DFCE start
cache.populate.on.start=true

#logback configuration
#the location of the config file: either a "classpath:" location
#(e.g. "classpath:myLogback.xml"), an absolute file URL
#(e.g. "file:C:/logback.xml), or a plain absolute path in the file system
#(e.g. "C:/logback.xml")
#logback.config.location=classpath:logback.xml
#refreshInterval interval between config file refresh checks, in milliseconds
#logback.refresh.interval=600000

#Spring Batch Job Configuration
job.commit.interval=15
job.parameters.date.format.pattern=yyyyMMddHHmmssSSS
job.dfce.home=target/dfce-job/home

#spark configuration
spark.master.url=spark://docuserv70.docubase.com:6066
spark.master.home=/opt/programs/spark/spark-1.6.2
#(file://) local to the spark master if spark.deploy.mode=cluster, local to spark home if client mode
spark.jobs.jar.path=file:///opt/programs/spark/work/spark-jobs.jar
#local to dfce webapp
spark.home=/opt/programs/spark/1.6.2/
spark.driver.memory=4g
spark.driver.cores=8
spark.executor.memory=8g
spark.deploy.mode=cluster
#Job email notification server
job.mail.enable=false
job.mail.host=docuserv21.docubase.com
job.mail.port=25
job.mail.protocol=smtp
job.mail.username=rd.notification@docuserv21.docubase.com
job.mail.password=
job.mail.encoding=UTF-8
#Job email template
job.mail.from=dfce@tessi.fr
job.mail.to=dfce@tessi.fr
job.mail.cc=
job.mail.bcc=

#Security strategy
#Possible value are 'default', 'cas', 'jwt', 'ldap' and 'activeDirectory'
#Or previous values combination like 'cas,ldap,default' (order preserving)
security.strategy=default

#Wether or not spring security should create a session (values are "stateless" and "ifRequired")
security.create-session=

#CAS
cas.auth.provider.id=T3551-DFCE
cas.security.check.server.url=https://localhost:8443/dfce-webapp
cas.server.url=
cas.ticket.validator.bean=defaultTicketValidator
cas.user.trust.assertion=false
cas.assertion.user.details.service=defaultCasAssertionUserDFCEDetailsService

#JWT
jwt.issuers=dfce
jwt.dfce.encrypted.secret=k984MdF/o1Sd7wHWOvDQ1w==
#Time in milliseconds between token creation date and expiration date (5 minutes)
jwt.expiresIn=300000
jwt.claims.user.details.service=defaultJwtClaimsUserDFCEDetailsService

#LDAP
ldap.server.url=ldap://localhost:389/dc=example,dc=com

#ldap authentification
ldap.user.search.filter=uid={0}
ldap.user.search.base=ou=Users
ldap.user.properties.separator=,
ldap.group.search.filter=uniqueMember={0}
ldap.group.search.base=ou=Groups
ldap.group.role.attribute=cn

#ACTIVE DIRECTORY
ad.server.url=ldap://localhost:389/
ad.server.domain=example.com

default.read.consistency.level=QUORUM
default.write.consistency.level=QUORUM

# Deferred File
# 2Mo
deferred.file.swap.threshold=2097152
deferred.file.name.prefix=com.docubase.dfce
deferred.file.name.suffix=.tmp

#Cryptography configuration
crypto.cypher.all=false
crypto.keystore.type=JCEKS
crypto.keystore.resource=classpath:/keyStore-demo.jks
crypto.keystore.encrypted.password=FzTR2aoTXo8hoQocaaTsGA==
crypto.keystore.provider=
crypto.two-step.mode=true
crypto.two-step.key.algorithm=AES
crypto.two-step.key.size=128

# Count or Duration (case Sensitive)
crypto.two-step.key.rotation=Count
crypto.two-step.key.rotation.count=10
crypto.two-step.key.rotation.duration.seconds=1

auto.versionning=false

#Restrictions policy
restrictions.policy.permissive=true

#Jobs configuration

#Massive Injector
#Thread pool configuration
injection.thread.pool.core.size=15
injection.thread.pool.max.size=15

#Items max processed by chunk
injection.chunk.batch.size=1000

#Injection configuration
injection.commit.interval=100
injection.thread.skip.limit=10

#Authentication
injection.username=
injection.password=

#Export Documents
#Thread pool configuration
export.thread.pool.core.size=4
export.thread.pool.max.size=4

#Items max processed by chunk
export.chunk.batch.size=1000
export.commit.interval=100

#Export configuration
export.zip.limit.size=3072

#Authentication
export.username=
export.password=

#Split/Merge index
move.index.read.interval=100
move.index.commit.interval=50

#Jobs sync strategy, should be async for production, and sync for tests
#Possible values : async, sync
job.sync.strategy=sync

#Jobs configuration End

# Timeout that keeps active sessions count (in seconds)
active.session.count.ttl=1800

# Document time series lifespan in seconds
# Should be at least a few days in order to let any job process data before it disappears
doc.timeseries.ttl=604800

# Lifecycle job thread pool (one thread will be used per rule)
lifecycle.thread.pool.core.size=4
lifecycle.thread.pool.max.size=4

# certificate : control
control.unique.document=false

# System profile : SAE, LOG_EVENTS_DOC, LOG_EVENTS_SYSTEM, LOG_EVENTS_ALL, INDEX_DOC, INDEX_DOC_ES, INDEX_FULLTEXT_ES, NO_INDEX_DOC, FS
# If no profile is selected, mode will Filesystem, which does not log document or system events, nor indexes documents.
dfce.mode=SAE

# CORS Information
# Origins and Headers are set to all by default with the * character.
# All methods are allowed by default. OPTIONS needs to be authorized for preflight requests
# Lists needs to be separated by comma without space.
allowed.origins=
allowed.credentials=true
allowed.methods=*
allowed.headers=*

spring.application.name=dfce
spring.cloud.config.uri=http://admin:admin@docuserv70:8761/config
spring.cloud.config.profile=dev
spring.cloud.config.label=master

# COLD Integration converter

# Starting point (X,Y) for the document. By default : 0,0
# Note : a marge of 10 is automatically applied.
#cold.document.position=0,0

# Define the default standard font : required.
# The built-in available fonts are :
# - CourierNew
# - Arial
# - TimesNewRoman
# - Symbol
# - ZapfDingbats
# - Courier
# - Helvetica
# Any other fonts may be added in the path defined in cold.fonts.path
cold.standard.font=Courier,8

# Define a set of available fonts for the areas
# For each font the values are :
# name : font name, required
# size : font size, required
# letter spacing : optional, default 0
# bold : 1=yes, optional, default 0
# italic : 1=yes, optional, default 0
# group : optional, default 0
# orientation (horizontal, vertical etc) : optional, default 0 (horizontal)
#cold.fonts={Courier:{15,1,0,0}}

# Define a set of colors.
# For each color, the values are :
# 0 < red < 255,
# 0 < green < 255,
# 0 < blue < 255,
# 0 < alpha < 255 : transparency, with 255 = opaque. By default : 255
# By default, black and white colors are defined.
#cold.colors={black:{0,0,0,255},white:{255,255,255}}

# Allow to define an area for all or internal pages (see code.style.area)
# The parameters are : x, y, width, height, font, text color, background color.
# The transparency applied is the one set for the text color.
# By default : no area defined
#cold.area=1,1,300,100,Courier,red,white

# Define the style area to apply for each pages.
# Possible values are : ALLPAGES, DOCUMENT or PAGES. By default : none
# With ALLPAGES, DOCUMENT : the cold.area values are used for all the pages.
# With DOCUMENT, no distinction made between pages for the rendering
# With PAGES : 'cold.area.begin' values are used for the first page
# and 'cold.area.end' values are used for the end page.
# The 'cold.area' values are used for the other pages
#cold.style.area=ALLPAGES

# Maximum number of lines on one page. By default : 256
cold.line.to.page=65

# Define the overlay parameters : x, y, width, height. By default : none
cold.overlay=100,200,300,420

# Define the character encoding for the input stream.
# By default : see 'cold.ansi'
cold.encoding=UTF-8

# Define the default encoding to use.
# YES : the value of the system property 'file.encoding', or UTF-8 if not set.
# NO (by default) : the 'ASCII' encoding is used.
#cold.ansi=NO

# Define the spacing between characters (x,y). By default : 0,0
cold.extra.leading=70,1

# Allow to define the orientation. Y = landscape, N = portrait. By default : N
#cold.landscape=N

# Allow to define a path containing some font files (*.ttf or *.ttc)
#cold.fonts.path=

# For the default text color, the values are :
# 0 < red < 255,
# 0 < green < 255,
# 0 < blue < 255,
# 0 < alpha < 255 : transparency, with 255 = opaque. By default : 255
# By default : black color
#cold.font.text.color=0,0,255
