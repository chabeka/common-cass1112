#Cassandra Configuration Properties
cassandra.cql.hosts=@GED.HOSTS_CASSANDRA_DFCE@
cassandra.cql.port=9042
cassandra.cluster.name=@GED.CASSANDRA_CLUSTER_NAME@
cassandra.cql.keyspace.name=dfce
cassandra.cql.consistency.read=QUORUM
cassandra.cql.consistency.write=QUORUM
cassandra.cql.max.local.connections=8
cassandra.cql.max.remote.connections=2
cassandra.cql.load.balancing.policy=com.datastax.driver.core.policies.RoundRobinPolicy
cassandra.cql.retry.policy=com.datastax.driver.core.policies.DefaultRetryPolicy
#Change to RF2 to get RF2 failover configuration
cassandra.keyspace.strategy=default
cassandra.replication.factor=1
cassandra.max.active.connections=200
cassandra.load.balancing.policy=me.prettyprint.cassandra.connection.RoundRobinBalancingPolicy

#Cassandra batch mode UNLOGGED, LOGGED, ASYNC
cassandra.batch.mode=LOGGED
#Cassandra authentication
cassandra.username=root
cassandra.password=regina4932

#number of rows in one page returned by the server
cassandra.paging.size=100

#Lock Strategy
#Possible value are zookeeper (zookeeperQuorum), zookeeperRF2, cassandra
lock.strategy=cassandra
cassandra.lock.ttl=5000

#Zookeeper
zookeeper.hosts=@GED.HOSTS_APPLI@

#ZookeeperRF2
#zookeeper.rf2.0.hosts=127.0.0.1:2181
#zookeeper.rf2.1.hosts=127.0.0.1:2182

#LifeCycle
life.cycle.default.length=10
life.cycle.default.unit=YEAR
life.cycle.default.thumbnail.page=1
life.cycle.default.thumbnail.size=TINY
life.cycle.default.thumbnail.quality=1.0
life.cycle.default.thumbnail.mime.type=image/jpeg


#Default search sort
search.default.sort.activated=false
search.default.sort.category.formatted.name=sm_archivage_date
search.default.sort.reversed=true

#Document
#Possible value are MD5, SHA, SHA-256, SHA-384 and SHA-512
document.message.digest.algorithm=SHA-1

#Chunk properties for file storage.
chunk.size=102400

dictionary.dao.max.query.size=100
#Range column size for counter update.
index.counter.query.size=5000 
index.reader.numdocs=10000
object.mapper.max.query.size=10000

#statistics 
stat.result.max.size=10000

#Lucandra
lucandra.indexname=DOCUBASE

supported.file.types=PDF,DOC,TXT,TMP,GZ,XML,TIF,TIFF,DOCX,DOCM,ODT,XLS,XLSX,XLSM,XLSB,ODS,JPG,JPEG,PNG,HTM,HTML,EML,ZIP,JPE,GIF,XPS,1,VCF,IMA,DTF,MHT,ATT,2,3,4,5,XML,6,7,RTF,8,BMP,9,10,EMZ,CSV,11,DOT,URL,12,15,MSO,16,NON,13,FAX,BCR,DSN,FMM,14,EXE,P7S,17,PPT,PPTX,PPTM,201,18,19,20,DS_,21,AXX,LST,LOG,9K%,VEG,2A3,25,33,DNT,0,26,24,27,32,22,AFF,28,DAT,29,JSF,30,CON,EDI,31,23,D%C,DU,FIC,FR,SOL,SAI,SAR,ROC,SVG,DEM,PD,DEP,MAN,UND,SXW,AGR,XLT,ASC,DSI,37,151,85,MEG,MUS,SNP,34,OXP,YAC,XXX,35,COM,RAP,LEB,KOP,RIB,36,MES,TI,UNI,%3D,_1_,_2_,2A3,AVI,BOR,COU,DE%,DRM,ENT,ENV,FIL,IMG,JUS,MOR,MSG,PAJ,PAR,PIE,POR,PRE,REF,RSI,SOG,TMP,WEB,XNK,164,248,657,1PD,9D6,BAP,BLO,DEC,DET,DUC,ECO,ICO,INI,JP2,LIA,MD,OIE,PAG,URS,237,AI,CCC,CRE,PAS,PAY,148,CHR,DAD,LA%,LNK,NOU,REN,SAL,WPS,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,7Z,AF%,BIN,DUE,FED,HEA,LET,M2,N%C,UNT,131,149,_FI,CAR,DAS,PHO,TRE,0,2,CAP,ETA,REC,SIT,TR,ZZD,123,500,519,716,776,860,867,897,AME,ANN,COP,DB,DOS,EXT,ODI,PLA,SMI,UKN,XLR,454,RAR,001,DO,LNV,LOC,NUM,ODP

daily.log.archive.base.name=DAILY_LOG_ARCHIVE_BASE
daily.log.archive.batch.size=50
event.jobs.log.periodicity=10000

#Cache configuration 
# global cache configuration,
# cache.max.entries : number of entries that can be cached. 
# cache.ttl : time to live in seconds. 
# cache.tti : time to idle in seconds. 
# each cache can have a specific configuration by adding : 
# cache.[cachename].max.entries : number of entries that can be cached. 
# cache.[cachename].ttl : time to live in seconds. 
# cache.[cachename].tti : time to idle in seconds. 
# available cache names are : base, metadata, chunk, compositeindexreference, contentrepository, file, indexreference, key, user, usergroup

cache.max.entries=100
cache.ttl=120
cache.tti=120

cache.metadata.max.entries=1000
cache.metadata.ttl=600
cache.metadata.tti=600

cache.chunk.max.entries=100
cache.chunk.ttl=600
cache.chunk.tti=300

cache.compositeindexreference.max.entries=1000
cache.compositeindexreference.ttl=600
cache.compositeindexreference.tti=600

cache.contentrepository.max.entries=100
cache.contentrepository.ttl=600
cache.contentrepository.tti=600

cache.file.max.entries=100
cache.file.ttl=600
cache.file.tti=600

cache.indexreference.max.entries=1000
cache.indexreference.ttl=600
cache.indexreference.tti=600

cache.key.max.entries=100
cache.key.ttl=180
cache.key.tti=180

cache.user.max.entries=100
cache.user.ttl=86400
cache.user.tti=86400

cache.usergroup.max.entries=100
cache.usergroup.ttl=86400
cache.usergroup.tti=86400


# pre-populate cache on DFCE start (true / false)
# set this to true if you want to pre-load "hot" caches on DFCE start
cache.populate.on.start=true

#logback configuration
#the location of the config file: either a "classpath:" location
#(e.g. "classpath:myLogback.xml"), an absolute file URL
#(e.g. "file:C:/logback.xml), or a plain absolute path in the file system
#(e.g. "C:/logback.xml")
#logback.config.location=classpath:logback.xml
#refreshInterval interval between config file refresh checks, in milliseconds
#logback.refresh.interval=600000

#Spring Batch Job Configuration
job.commit.interval=15
job.parameters.date.format.pattern=yyyyMMddHHmmssSSS
job.dfce.home=target/dfce-job/home

#spark configuration 
spark.master.url=spark://docuserv70.docubase.com:6066
spark.master.home=/opt/programs/spark/spark-1.6.2
#(file://) local to the spark master if spark.deploy.mode=cluster, local to spark home if client mode
spark.jobs.jar.path=file:///opt/programs/spark/work/spark-jobs.jar
#local to dfce webapp
spark.home=/opt/programs/spark/1.6.2/
spark.driver.memory=4g
spark.driver.cores=8
spark.executor.memory=8g
#Job email notification server
job.mail.enable=false
job.mail.host=docuserv21.docubase.com
job.mail.port=25
job.mail.protocol=smtp
job.mail.username=rd.notification@docuserv21.docubase.com
job.mail.password=
job.mail.encoding=UTF-8
#Job email template
job.mail.from=dfce@tessi.fr
job.mail.to=dfce@tessi.fr
job.mail.cc=
job.mail.bcc=

#Security strategy
#Possible value are 'default', 'cas', 'jwt', 'ldap' and 'activeDirectory'
#Or previous values combination like 'cas,ldap,default' (order preserving)  
security.strategy=default

#Wether or not spring security should create a session (values are "stateless" and "ifRequired")
security.create-session=

#CAS
cas.auth.provider.id=T3551-DFCE
cas.security.check.server.url=https://localhost:8443/dfce-webapp
cas.server.url=
cas.ticket.validator.bean=defaultTicketValidator
cas.user.trust.assertion=false
cas.assertion.user.details.service=defaultCasAssertionUserDFCEDetailsService

#JWT
jwt.encrypted.secret=a0e8a15a90e3e2b8
jwt.issuer=dfce
#Time in milliseconds between token creation date and expiration date (5 minutes)
jwt.expiresIn=300000
jwt.claims.user.details.service=defaultJwtClaimsUserDFCEDetailsService

#LDAP
ldap.server.url=ldap://localhost:389/dc=example,dc=com

#ldap authentification
ldap.user.search.filter=uid={0}
ldap.user.search.base=ou=Users
ldap.user.properties.separator=,
ldap.group.search.filter=uniqueMember={0}
ldap.group.search.base=ou=Groups
ldap.group.role.attribute=cn

#ACTIVE DIRECTORY
ad.server.url=ldap://localhost:389/
ad.server.domain=example.com

default.read.consistency.level=QUORUM
default.write.consistency.level=QUORUM

# Deferred File
# 2Mo
deferred.file.swap.threshold=2097152
deferred.file.name.prefix=com.docubase.dfce
deferred.file.name.suffix=.tmp

#Cryptography configuration
crypto.keystore.type=JCEKS
crypto.keystore.resource=classpath:/keyStore-demo.jks
crypto.keystore.encrypted.password=c5b3691c28cd86207461aea10812ced7
crypto.keystore.provider=

auto.versionning=false

#Restrictions policy
restrictions.policy.permissive=true

#Jobs configuration

#Massive Injector
#Thread pool configuration
injection.thread.pool.core.size=15
injection.thread.pool.max.size=15

#Items max processed by chunk
injection.chunk.batch.size=1000

#Injection configuration
injection.commit.interval=100
injection.thread.skip.limit=10

#Authentication
injection.username=
injection.password=

#Export Documents
#Thread pool configuration
export.thread.pool.core.size=4
export.thread.pool.max.size=4

#Items max processed by chunk
export.chunk.batch.size=1000
export.commit.interval=100

#Export configuration
export.zip.limit.size=3072

#Authentication
export.username=
export.password=

#Split/Merge index
move.index.read.interval=100
move.index.commit.interval=50

#Jobs sync strategy, should be async for production, and sync for tests
#Possible values : async, sync
job.sync.strategy=sync

#Jobs configuration End

# Timeout that keeps active sessions count (in seconds)
active.session.count.ttl=1800

# Document time series lifespan in seconds
# Should be at least a few days in order to let any job process data before it disappears
doc.timeseries.ttl=604800

# Lifecycle job thread pool (one thread will be used per rule)
lifecycle.thread.pool.core.size=4
lifecycle.thread.pool.max.size=4

# certificate : control
control.unique.document=false

# System profile : SAE, LOG_EVENTS_DOC, LOG_EVENTS_SYSTEM, LOG_EVENTS_ALL, INDEX_DOC, FS
# If no profile is selected, mode will Filesystem, which does not log document or system events, nor indexes documents.
dfce.mode=SAE

# CORS Information
# Origins and Headers are set to all by default with the * character.
# All methods are allowed by default. OPTIONS needs to be authorized for preflight requests
# Lists needs to be separated by comma without space.
allowed.origins=
allowed.credentials=true
allowed.methods=*
allowed.headers=*

spring.application.name=dfce
spring.cloud.config.uri=http://admin:admin@docuserv70:8761/config
spring.cloud.config.profile=dev
spring.cloud.config.label=master

